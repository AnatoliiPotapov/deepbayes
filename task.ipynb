{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Вступительное задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## ШКОЛА ПО БАЙЕСОВСКИМ МЕТОДАМ В ГЛУБИННОМ ОБУЧЕНИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Летняя школа по современным методам глубинного обучения и байесовскому подходу\n",
    "\n",
    "26-31 августа 2017, Москва"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Потапов Анатолий 4115 ФБМФ МФТИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Минимизируем функцию:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![formula](images/formula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import special\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Используйте scipy.special для вычисления численно неустойчивых функций\n",
    "https://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lossf(w, X, y, l1, l2):\n",
    "    \"\"\"\n",
    "    Вычисление функции потерь.\n",
    "\n",
    "    :param w: numpy.array размера  (M,) dtype = np.float\n",
    "    :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "    :param y: numpy.array размера  (N,), dtype = np.int\n",
    "    :param l1: float, l1 коэффициент регуляризатора \n",
    "    :param l2: float, l2 коэффициент регуляризатора \n",
    "    :return: float, value of loss function\n",
    "    \"\"\"\n",
    "    def stable_log1exp(x):\n",
    "        big = (x > 35.0)*1.0\n",
    "        big = big * x\n",
    "        small = (x < 35.0)*1.0\n",
    "        small = small * x\n",
    "        small = np.log(1 + np.exp(small))\n",
    "        return big+small\n",
    "    \n",
    "    # Вам необходимо вычислить значение функции потерь тут, решение может занимать 1 строку\n",
    "    lossf = np.sum(stable_log1exp(-y*np.sum(X*w, axis=1))) + l1*np.sum(np.abs(w)) + l2*np.sum(w**2) \n",
    "    return lossf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gradf(w, X, y, l1, l2):\n",
    "    \"\"\"\n",
    "    Вычисление градиента функции потерь.\n",
    "\n",
    "    :param w: numpy.array размера  (M,), dtype = np.float\n",
    "    :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "    :param y: numpy.array размера  (N,), dtype = np.int\n",
    "    :param l1: float, l1 коэффициент регуляризатора \n",
    "    :param l2: float, l2 коэффициент регуляризатора \n",
    "    :return: numpy.array размера  (M,), dtype = np.float, gradient vector d lossf / dw\n",
    "    \"\"\"\n",
    "    \n",
    "    # Вам необходимо вычислить градиент функции потерь тут, решение может занимать 1 строку\n",
    "        \n",
    "    gradw = np.sum(\n",
    "        special.expit(-y*np.sum(X*w, axis=1))[:, np.newaxis] * (-y[:, np.newaxis]*X),\n",
    "        axis = 0\n",
    "    ) + 2*l2*np.abs(w) + l1*np.sign(w)\n",
    "    \n",
    "    return gradw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LR(ClassifierMixin, BaseEstimator):\n",
    "    \n",
    "    def __init__(self, lr=1, l1=1e-4, l2=1e-4, num_iter=1000, verbose=0):\n",
    "        self.l1 = l1\n",
    "        self.l2 = l2\n",
    "        self.w = None\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        self.num_iter = num_iter\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Обучение логистической регрессии.\n",
    "        Настраивает self.w коэффициенты модели.\n",
    "\n",
    "        Если self.verbose == True, то выводите значение \n",
    "        функции потерь на итерациях метода оптимизации. \n",
    "\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :param y: numpy.array размера  (N,), dtype = np.int\n",
    "        :return: self\n",
    "        \"\"\"\n",
    "        n, d = X.shape\n",
    " \n",
    "        # Задайте начальное приближение вектора весов\n",
    "        w = np.random.uniform(low=-1.0, high=1.0, size=d)\n",
    "        \n",
    "        # Настройте параметры функции потерь с помощью градиентного спуска   \n",
    "        for iter in range(self.num_iter):\n",
    "            grad = gradf(w, X, y, self.l1, self.l2)\n",
    "            w = np.add(w, -self.lr*grad)\n",
    "            # Вывод функции потерь\n",
    "            if self.verbose == True and iter % 30 == 0:\n",
    "                print \"Значение функции потерь на итерации {0}: {1}\".format(iter, lossf(w, X, y, self.l1, self.l2))\n",
    "               \n",
    "        self.w = w\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание вероятности принадлежности объекта к классу 1.\n",
    "        Возвращает np.array размера (N,) чисел в отрезке от 0 до 1.\n",
    "\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return: numpy.array размера  (N,), dtype = np.int\n",
    "        \"\"\"\n",
    "        # Вычислите вероятности принадлежности каждого \n",
    "        # объекта из X к положительному классу, используйте\n",
    "        # эту функцию для реализации LR.predict\n",
    "        \n",
    "        probs = special.expit(np.sum(X*self.w, axis=1))\n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание класса для объекта.\n",
    "        Возвращает np.array размера (N,) элементов 1 или -1.\n",
    "\n",
    "        :param X: numpy.array размера  (N, M), dtype = np.float\n",
    "        :return:  numpy.array размера  (N,), dtype = np.int\n",
    "        \"\"\"\n",
    "\n",
    "        # Вычислите предсказания для каждого объекта из X\n",
    "        predicts = np.sign(np.sum(X*self.w, axis=1))\n",
    "        return predicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test_work():\n",
    "    print \"Start test\"\n",
    "    X, y = make_classification(n_features=100, n_samples=1000)\n",
    "    y = 2 * (y - 0.5)\n",
    "\n",
    "    try:\n",
    "        clf = LR(lr=1, l1=1e-4, l2=1e-4, num_iter=1000, verbose=0)\n",
    "    except Exception:\n",
    "        assert False, \"Создание модели завершается с ошибкой\"\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        clf = clf.fit(X, y)\n",
    "    except Exception:\n",
    "        assert False, \"Обучение модели завершается с ошибкой\"\n",
    "        return\n",
    "\n",
    "    assert isinstance(lossf(clf.w, X, y, 1e-3, 1e-3), float), \"Функция потерь должна быть скалярной и иметь тип np.float\"\n",
    "    assert gradf(clf.w, X, y, 1e-3, 1e-3).shape == (100,), \"Размерность градиента должна совпадать с числом параметров\"\n",
    "    assert gradf(clf.w, X, y, 1e-3, 1e-3).dtype == np.float, \"Вектор градиента, должен состоять из элементов типа np.float\"\n",
    "    assert clf.predict(X).shape == (1000,), \"Размер вектора предсказаний, должен совпадать с количеством объектов\"\n",
    "    assert np.min(clf.predict_proba(X)) >= 0, \"Вероятности должны быть не меньше, чем 0\"\n",
    "    assert np.max(clf.predict_proba(X)) <= 1, \"Вероятности должны быть не больше, чем 1\"\n",
    "    assert len(set(clf.predict(X))) == 2, \"Метод предсказывает больше чем 2 класса на двух классовой задаче\"\n",
    "    print \"End tests\"\n",
    "def test_work():\n",
    "    print \"Start test\"\n",
    "    X, y = make_classification(n_features=100, n_samples=1000)\n",
    "    y = 2 * (y - 0.5)\n",
    "\n",
    "    try:\n",
    "        clf = LR(lr=1, l1=1e-4, l2=1e-4, num_iter=1000, verbose=0)\n",
    "    except Exception:\n",
    "        assert False, \"Создание модели завершается с ошибкой\"\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        clf = clf.fit(X, y)\n",
    "    except Exception:\n",
    "        assert False, \"Обучение модели завершается с ошибкой\"\n",
    "        return\n",
    "\n",
    "    assert isinstance(lossf(clf.w, X, y, 1e-3, 1e-3), float), \"Функция потерь должна быть скалярной и иметь тип np.float\"\n",
    "    assert gradf(clf.w, X, y, 1e-3, 1e-3).shape == (100,), \"Размерность градиента должна совпадать с числом параметров\"\n",
    "    assert gradf(clf.w, X, y, 1e-3, 1e-3).dtype == np.float, \"Вектор градиента, должен состоять из элементов типа np.float\"\n",
    "    assert clf.predict(X).shape == (1000,), \"Размер вектора предсказаний, должен совпадать с количеством объектов\"\n",
    "    assert np.min(clf.predict_proba(X)) >= 0, \"Вероятности должны быть не меньше, чем 0\"\n",
    "    assert np.max(clf.predict_proba(X)) <= 1, \"Вероятности должны быть не больше, чем 1\"\n",
    "    assert len(set(clf.predict(X))) == 2, \"Метод предсказывает больше чем 2 класса на двух классовой задаче\"\n",
    "    print \"End tests\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значение функции потерь на итерации 0: 35893.1886814\n",
      "Значение функции потерь на итерации 30: 5013.91289013\n",
      "Значение функции потерь на итерации 60: 3750.69311214\n",
      "Значение функции потерь на итерации 90: 5503.63775143\n",
      "Значение функции потерь на итерации 120: 4722.56329836\n",
      "Значение функции потерь на итерации 150: 4608.45094853\n",
      "Значение функции потерь на итерации 180: 4966.84668066\n",
      "Значение функции потерь на итерации 210: 5137.20498881\n",
      "Значение функции потерь на итерации 240: 4984.76734963\n",
      "Значение функции потерь на итерации 270: 3639.77447642\n",
      "Значение функции потерь на итерации 300: 4752.3372167\n",
      "Значение функции потерь на итерации 330: 4223.96410167\n",
      "Значение функции потерь на итерации 360: 4740.21330235\n",
      "Значение функции потерь на итерации 390: 4024.0010114\n",
      "Значение функции потерь на итерации 420: 4125.11380716\n",
      "Значение функции потерь на итерации 450: 4705.56271358\n",
      "Значение функции потерь на итерации 480: 5415.69780755\n",
      "Значение функции потерь на итерации 510: 4728.99424243\n",
      "Значение функции потерь на итерации 540: 3780.11696446\n",
      "Значение функции потерь на итерации 570: 4485.6970045\n",
      "Значение функции потерь на итерации 600: 4417.26193275\n",
      "Значение функции потерь на итерации 630: 4159.54744507\n",
      "Значение функции потерь на итерации 660: 4352.60755364\n",
      "Значение функции потерь на итерации 690: 5133.93865895\n",
      "Значение функции потерь на итерации 720: 3826.8779274\n",
      "Значение функции потерь на итерации 750: 4867.57464232\n",
      "Значение функции потерь на итерации 780: 4295.16616613\n",
      "Значение функции потерь на итерации 810: 4666.5342834\n",
      "Значение функции потерь на итерации 840: 5000.18719499\n",
      "Значение функции потерь на итерации 870: 5157.90826705\n",
      "Значение функции потерь на итерации 900: 5542.44719211\n",
      "Значение функции потерь на итерации 930: 4016.53654868\n",
      "Значение функции потерь на итерации 960: 5335.83971738\n",
      "Значение функции потерь на итерации 990: 5151.56271901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  -0.54918831,  -14.89467622,   27.88663558,   -7.88867535,\n",
       "        139.44070388,    6.73912665,  -19.48138449,    0.31787488,\n",
       "        -16.39913365,  -26.20424781,    7.36188869,  -15.58978978,\n",
       "         -7.94986454,  -10.11484377,  112.28848107,   -2.09364613,\n",
       "        -30.42715269,   12.70918451,   13.9134559 ,    9.36732763,\n",
       "        -13.59677232,  -18.39172443,  -19.94171865,    6.87963925,\n",
       "         -0.34838264,   -2.13734373,  -20.64818967,   -1.30783227,\n",
       "         -4.90367623,  -31.4108649 ,   -3.09932777,  -42.56933656,\n",
       "          7.01175395,    2.2927014 ,   13.19433416,  -21.25098747,\n",
       "          4.44785808,  -50.16201286,    7.08526424,    9.49000819,\n",
       "         -7.64863948,  -11.67983641,   19.01551455,   -6.21290313,\n",
       "        -17.1238397 ,   -3.69029826,   -9.30525685,   -8.23028356,\n",
       "         -8.96479667,    8.32324949,   10.51243472,   13.18674271,\n",
       "          9.7638033 ,  200.79443807,   -7.28313823,   29.72267359,\n",
       "        -24.42873802,   32.00525683,  -28.49309366,   12.97418075,\n",
       "        -22.25085075,   -7.3174272 ,  -11.40038211,   -5.9681876 ,\n",
       "         -4.90303997,  -12.43967895,   -6.65863842,   -4.07823303,\n",
       "        -21.75302709,    0.78532934,   -5.60515635,   -2.54112996,\n",
       "          8.33023382,   14.31542979,  -21.8510619 ,   10.3691103 ,\n",
       "         -4.14277557,   27.55644707,  -14.85318835,   37.66314535,\n",
       "         17.84121803,  -27.27513167,    3.16571657,    9.28310255,\n",
       "        -15.13015217,    5.17542289,   14.70387145,   -7.45391151,\n",
       "        -34.39334221,   16.7671928 ,    7.81318954,   26.51769562,\n",
       "          9.84230936,  -10.37543833,   10.161255  ,   -3.96580271,\n",
       "        -21.57388183,   16.88047645,   23.91097424,  -10.51601635])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = make_classification(n_features=100, n_samples=1000)\n",
    "y = 2 * (y - 0.5)\n",
    "clf = LR(lr= 1, l1=1e-4, l2=1e-4, num_iter=1000, verbose=True)\n",
    "clf = clf.fit(X, y)\n",
    "clf.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start test\n",
      "End tests\n"
     ]
    }
   ],
   "source": [
    "test_work()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test how our model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=100, n_samples=1000)\n",
    "y = 2 * (y - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Sklearn native logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "scikit_lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 ms, sys: 4 ms, total: 36 ms\n",
      "Wall time: 34 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scikit_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit model accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "print \"Scikit model accuracy: {0}\".format(accuracy_score(y_test, scikit_lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### My logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_lr = LR(lr=1, l1=0, l2=0, num_iter=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 764 ms, sys: 412 ms, total: 1.18 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_lr = my_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My model accuracy: 0.905\n"
     ]
    }
   ],
   "source": [
    "print \"My model accuracy: {0}\".format(accuracy_score(y_test, my_lr.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mipt-trends2.7",
   "language": "python",
   "name": "mipt-trends2.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
